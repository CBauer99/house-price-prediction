# **Predicting House Prices using Regression Analysis**

## **Project Overview:**
*Objective:*

Model to predict house prices based on various features utilizing the ***Boston Housing Dataset***

  
*Dataset:*  
The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic prices and the demand for clean air', J. Environ. Economics & Management, vol.5, 81-102, 1978. Used in Belsley, Kuh & Welsch, 'Regression diagnostics
 ...', Wiley, 1980.   N.B. Various transformations are used in the table on
 pages 244-261 of the latter.

  
The dataset contains the following columns:
- `CRIM`: per capita crime rate by town
- `ZN`: proportion of residential land zoned for lots over 25,000 sq. ft.
- `INDUS`: proportion of non-retail business acres per town
- `CHAS`: Charles River dummy variable (1 if tract bounds river; 0 otherwise)
- `NOX`: nitrogen oxides concentration (parts per 10 million)
- `RM`: average number of rooms per dwelling
- `AGE`: proportion of owner-occupied units built prior to 1940
- `DIS`: weighted mean of distances to five Boston employment centers
- `RAD`: index of accessibility to radial highways
- `TAX`: full-value property tax rate per $10,000
- `PTRATIO`: pupil-teacher ratio by town
- `B`: 1000(Bk - 0.63)^2 where Bk is the proportion of Black residents by town
- `LSTAT`: percentage of lower status of the population
- `MEDV`: median value of owner-occupied homes in $1000s

  
*Steps:*
1. Data Exploration: Explore the dataset to understand its structure and features.
2. Data Preprocessing: Clean the data, handle missing values, and transform categorical variables if necessary.
3. Feature Engineering: Create new features or transform existing ones that might improve model performance.
4. Model Selection: Choose appropriate regression models (e.g., Linear Regression, Decision Trees, Random Forests).
5. Model Training: Train the models on the dataset and evaluate their performance using metrics like RMSE (Root Mean Squared Error).
6. Model Tuning: Fine-tune hyperparameters of the chosen model to improve performance.
7. Validation: Validate the model using cross-validation techniques to ensure it generalizes well.
8. Deployment: If possible, deploy the model using a simple web interface (optional, but adds to portfolio appeal).

 
*Goals:*
- Gain experience in data cleaning, preprocessing, feature engineering, and model selection.
- Understand evaluation metrics and how to interpret them in the context of regression problems.
- Showcase ability to handle a complete data science pipeline from data exploration to model deployment.

 
*Presentation:*
- [ ] Document process, findings, and insights in a structured report or Jupyter notebook.
- [ ] Include visualizations (e.g., scatter plots, heatmaps) to illustrate relationships between variables.
- [ ] Explain decisions and interpretations clearly to demonstrate your understanding.
